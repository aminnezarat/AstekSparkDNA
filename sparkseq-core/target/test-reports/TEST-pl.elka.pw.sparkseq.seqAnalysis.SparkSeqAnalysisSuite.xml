<?xml version="1.0" encoding="UTF-8" ?>
<testsuite 
errors="0" failures="3" hostname="sparkseq001" name="pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite" tests="3" time="7.18" timestamp="2014-02-22T12:28:18">
  <properties>
    <property name="jline.esc.timeout" value="0"> </property>
    <property name="java.runtime.name" value="Java(TM) SE Runtime Environment">
    </property>
    <property 
    name="sun.boot.library.path" value="/usr/lib/jvm/java-6-oracle/jre/lib/amd64">
</property>
    <property name="java.vm.version" value="20.45-b01"> </property>
    <property name="java.vm.vendor" value="Sun Microsystems Inc."> </property>
    <property name="java.vendor.url" value="http://java.sun.com/"> </property>
    <property name="path.separator" value=":"> </property>
    <property name="java.vm.name" value="Java HotSpot(TM) 64-Bit Server VM">
    </property>
    <property name="file.encoding.pkg" value="sun.io"> </property>
    <property name="user.country" value="US"> </property>
    <property name="sun.java.launcher" value="SUN_STANDARD"> </property>
    <property name="sun.os.patch.level" value="unknown"> </property>
    <property 
    name="java.vm.specification.name" value="Java Virtual Machine Specification">
</property>
    <property name="user.dir" value="/home/mesos/phd/sparkseq"> </property>
    <property name="java.runtime.version" value="1.6.0_45-b06"> </property>
    <property 
    name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment">
</property>
    <property 
    name="java.endorsed.dirs" value="/usr/lib/jvm/java-6-oracle/jre/lib/endorsed">
</property>
    <property name="os.arch" value="amd64"> </property>
    <property name="java.io.tmpdir" value="/tmp"> </property>
    <property name="line.separator" value=" "> </property>
    <property 
    name="java.vm.specification.vendor" value="Sun Microsystems Inc.">
</property>
    <property name="os.name" value="Linux"> </property>
    <property name="sun.jnu.encoding" value="UTF-8"> </property>
    <property 
    name="java.library.path" value="/usr/lib/jvm/java-6-oracle/jre/lib/amd64/server:/usr/lib/jvm/java-6-oracle/jre/lib/amd64:/usr/lib/jvm/java-6-oracle/jre/../lib/amd64:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib">
</property>
    <property 
    name="java.specification.name" value="Java Platform API Specification">
</property>
    <property name="java.class.version" value="50.0"> </property>
    <property 
    name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers">
</property>
    <property name="os.version" value="3.2.0-58-virtual"> </property>
    <property name="user.home" value="/home/mesos"> </property>
    <property name="user.timezone" value="Etc/UTC"> </property>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob">
    </property>
    <property name="file.encoding" value="UTF-8"> </property>
    <property name="java.specification.version" value="1.6"> </property>
    <property name="user.name" value="mesos"> </property>
    <property 
    name="java.class.path" value="/usr/local/share/sbt/bin/sbt-launch.jar">
</property>
    <property name="jline.shutdownhook" value="false"> </property>
    <property name="java.vm.specification.version" value="1.0"> </property>
    <property name="sun.arch.data.model" value="64"> </property>
    <property name="java.home" value="/usr/lib/jvm/java-6-oracle/jre">
    </property>
    <property 
    name="sun.java.command" value="/usr/local/share/sbt/bin/sbt-launch.jar test">
</property>
    <property name="java.specification.vendor" value="Sun Microsystems Inc.">
    </property>
    <property name="user.language" value="en"> </property>
    <property name="java.vm.info" value="mixed mode"> </property>
    <property name="java.version" value="1.6.0_45"> </property>
    <property 
    name="java.ext.dirs" value="/usr/lib/jvm/java-6-oracle/jre/lib/ext:/usr/java/packages/lib/ext">
</property>
    <property 
    name="sun.boot.class.path" value="/usr/lib/jvm/java-6-oracle/jre/lib/resources.jar:/usr/lib/jvm/java-6-oracle/jre/lib/rt.jar:/usr/lib/jvm/java-6-oracle/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-6-oracle/jre/lib/jsse.jar:/usr/lib/jvm/java-6-oracle/jre/lib/jce.jar:/usr/lib/jvm/java-6-oracle/jre/lib/charsets.jar:/usr/lib/jvm/java-6-oracle/jre/lib/modules/jdk.boot.jar:/usr/lib/jvm/java-6-oracle/jre/classes">
</property>
    <property name="java.vendor" value="Sun Microsystems Inc."> </property>
    <property name="file.separator" value="/"> </property>
    <property 
    name="java.vendor.url.bug" value="http://java.sun.com/cgi-bin/bugreport.cgi">
</property>
    <property name="sun.cpu.endian" value="little"> </property>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"> </property>
    <property name="sun.cpu.isalist" value=""> </property>
  </properties>
  <testcase 
  name="Test region count" classname="pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite" time="4.127">
    <failure 
    message="Input path does not exist: file:/home/mesos/phd/sparkseq-core/src/test/resources/sample_1.bed" type="class org.apache.hadoop.mapred.InvalidInputException">
      org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/home/mesos/phd/sparkseq-core/src/test/resources/sample_1.bed
      at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:197)
      at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:208)
      at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:140)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.MappedRDD.getPartitions(MappedRDD.scala:28)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.MappedRDD.getPartitions(MappedRDD.scala:28)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.MappedRDD.getPartitions(MappedRDD.scala:28)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.SparkContext.runJob(SparkContext.scala:898)
      at org.apache.spark.rdd.RDD.collect(RDD.scala:602)
      at org.apache.spark.rdd.RDD.toArray(RDD.scala:609)
      at pl.elka.pw.sparkseq.conversions.SparkSeqConversions$.BEDFileToHashMap(SparkSeqConversions.scala:137)
      at pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite$$anonfun$1.apply$mcV$sp(SparkSeqAnalysisSuite.scala:15)
      at pl.elka.pw.sparkseq.util.SparkFunSuite$$anonfun$sparkSeqTest$1.apply$mcV$sp(SparkSeqFunSuite.scala:38)
      at pl.elka.pw.sparkseq.util.SparkFunSuite$$anonfun$sparkSeqTest$1.apply(SparkSeqFunSuite.scala:34)
      at pl.elka.pw.sparkseq.util.SparkFunSuite$$anonfun$sparkSeqTest$1.apply(SparkSeqFunSuite.scala:34)
      at org.scalatest.Transformer$$anonfun$apply$1.apply(Transformer.scala:22)
      at org.scalatest.Transformer$$anonfun$apply$1.apply(Transformer.scala:22)
      at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
      at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
      at org.scalatest.Transformer.apply(Transformer.scala:22)
      at org.scalatest.Transformer.apply(Transformer.scala:20)
      at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:158)
      at org.scalatest.Suite$class.withFixture(Suite.scala:1121)
      at org.scalatest.FunSuite.withFixture(FunSuite.scala:1559)
      at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:155)
      at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:167)
      at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:167)
      at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
      at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:167)
      at pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite.org$scalatest$BeforeAndAfter$$super$runTest(SparkSeqAnalysisSuite.scala:11)
      at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
      at pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite.runTest(SparkSeqAnalysisSuite.scala:11)
      at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:200)
      at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:200)
      at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
      at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
      at scala.collection.immutable.List.foreach(List.scala:318)
      at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
      at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
      at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
      at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:200)
      at org.scalatest.FunSuite.runTests(FunSuite.scala:1559)
      at org.scalatest.Suite$class.run(Suite.scala:1423)
      at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1559)
      at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:204)
      at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:204)
      at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
      at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:204)
      at pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite.org$scalatest$BeforeAndAfter$$super$run(SparkSeqAnalysisSuite.scala:11)
      at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
      at pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite.run(SparkSeqAnalysisSuite.scala:11)
      at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:442)
      at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:649)
      at sbt.TestRunner.runTest$1(TestFramework.scala:84)
      at sbt.TestRunner.run(TestFramework.scala:94)
      at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:224)
      at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:224)
      at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:212)
      at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:224)
      at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:224)
      at sbt.TestFunction.apply(TestFramework.scala:229)
      at sbt.Tests$$anonfun$7.apply(Tests.scala:196)
      at sbt.Tests$$anonfun$7.apply(Tests.scala:196)
      at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:45)
      at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:45)
      at sbt.std.Transform$$anon$4.work(System.scala:64)
      at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:237)
      at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:237)
      at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:18)
      at sbt.Execute.work(Execute.scala:244)
      at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:237)
      at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:237)
      at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:160)
      at sbt.CompletionService$$anon$2.call(CompletionService.scala:30)
      at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
      at java.util.concurrent.FutureTask.run(FutureTask.java:138)
      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
      at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
      at java.util.concurrent.FutureTask.run(FutureTask.java:138)
      at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
      at java.lang.Thread.run(Thread.java:662)
</failure>
</testcase>
  <testcase 
  name="Test base count" classname="pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite" time="1.512">
    <failure 
    message="Input path does not exist: file:/home/mesos/phd/sparkseq-core/src/test/resources/sample_1.bam" type="class org.apache.hadoop.mapreduce.lib.input.InvalidInputException">
      org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/mesos/phd/sparkseq-core/src/test/resources/sample_1.bam
      at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:235)
      at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:252)
      at fi.tkk.ics.hadoop.bam.BAMInputFormat.getSplits(BAMInputFormat.java:75)
      at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:75)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.MappedRDD.getPartitions(MappedRDD.scala:28)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:31)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.FlatMappedRDD.getPartitions(FlatMappedRDD.scala:30)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.UnionRDD$$anonfun$1.apply(UnionRDD.scala:52)
      at org.apache.spark.rdd.UnionRDD$$anonfun$1.apply(UnionRDD.scala:52)
      at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
      at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
      at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
      at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
      at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
      at scala.collection.AbstractTraversable.map(Traversable.scala:105)
      at org.apache.spark.rdd.UnionRDD.getPartitions(UnionRDD.scala:52)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.FilteredRDD.getPartitions(FilteredRDD.scala:28)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.RDD.take(RDD.scala:824)
      at org.apache.spark.rdd.RDD.first(RDD.scala:856)
      at pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite$$anonfun$2.apply$mcV$sp(SparkSeqAnalysisSuite.scala:23)
      at pl.elka.pw.sparkseq.util.SparkFunSuite$$anonfun$sparkSeqTest$1.apply$mcV$sp(SparkSeqFunSuite.scala:38)
      at pl.elka.pw.sparkseq.util.SparkFunSuite$$anonfun$sparkSeqTest$1.apply(SparkSeqFunSuite.scala:34)
      at pl.elka.pw.sparkseq.util.SparkFunSuite$$anonfun$sparkSeqTest$1.apply(SparkSeqFunSuite.scala:34)
      at org.scalatest.Transformer$$anonfun$apply$1.apply(Transformer.scala:22)
      at org.scalatest.Transformer$$anonfun$apply$1.apply(Transformer.scala:22)
      at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
      at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
      at org.scalatest.Transformer.apply(Transformer.scala:22)
      at org.scalatest.Transformer.apply(Transformer.scala:20)
      at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:158)
      at org.scalatest.Suite$class.withFixture(Suite.scala:1121)
      at org.scalatest.FunSuite.withFixture(FunSuite.scala:1559)
      at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:155)
      at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:167)
      at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:167)
      at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
      at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:167)
      at pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite.org$scalatest$BeforeAndAfter$$super$runTest(SparkSeqAnalysisSuite.scala:11)
      at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
      at pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite.runTest(SparkSeqAnalysisSuite.scala:11)
      at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:200)
      at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:200)
      at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
      at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
      at scala.collection.immutable.List.foreach(List.scala:318)
      at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
      at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
      at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
      at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:200)
      at org.scalatest.FunSuite.runTests(FunSuite.scala:1559)
      at org.scalatest.Suite$class.run(Suite.scala:1423)
      at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1559)
      at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:204)
      at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:204)
      at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
      at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:204)
      at pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite.org$scalatest$BeforeAndAfter$$super$run(SparkSeqAnalysisSuite.scala:11)
      at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
      at pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite.run(SparkSeqAnalysisSuite.scala:11)
      at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:442)
      at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:649)
      at sbt.TestRunner.runTest$1(TestFramework.scala:84)
      at sbt.TestRunner.run(TestFramework.scala:94)
      at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:224)
      at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:224)
      at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:212)
      at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:224)
      at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:224)
      at sbt.TestFunction.apply(TestFramework.scala:229)
      at sbt.Tests$$anonfun$7.apply(Tests.scala:196)
      at sbt.Tests$$anonfun$7.apply(Tests.scala:196)
      at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:45)
      at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:45)
      at sbt.std.Transform$$anon$4.work(System.scala:64)
      at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:237)
      at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:237)
      at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:18)
      at sbt.Execute.work(Execute.scala:244)
      at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:237)
      at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:237)
      at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:160)
      at sbt.CompletionService$$anon$2.call(CompletionService.scala:30)
      at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
      at java.util.concurrent.FutureTask.run(FutureTask.java:138)
      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
      at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
      at java.util.concurrent.FutureTask.run(FutureTask.java:138)
      at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
      at java.lang.Thread.run(Thread.java:662)
</failure>
</testcase>
  <testcase 
  name="Test base count with filtered region" classname="pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite" time="1.461">
    <failure 
    message="Input path does not exist: file:/home/mesos/phd/sparkseq-core/src/test/resources/sample_1.bam" type="class org.apache.hadoop.mapreduce.lib.input.InvalidInputException">
      org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/mesos/phd/sparkseq-core/src/test/resources/sample_1.bam
      at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:235)
      at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:252)
      at fi.tkk.ics.hadoop.bam.BAMInputFormat.getSplits(BAMInputFormat.java:75)
      at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:75)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.MappedRDD.getPartitions(MappedRDD.scala:28)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.FilteredRDD.getPartitions(FilteredRDD.scala:28)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:31)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.FlatMappedRDD.getPartitions(FlatMappedRDD.scala:30)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.UnionRDD$$anonfun$1.apply(UnionRDD.scala:52)
      at org.apache.spark.rdd.UnionRDD$$anonfun$1.apply(UnionRDD.scala:52)
      at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
      at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
      at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
      at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
      at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
      at scala.collection.AbstractTraversable.map(Traversable.scala:105)
      at org.apache.spark.rdd.UnionRDD.getPartitions(UnionRDD.scala:52)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.FilteredRDD.getPartitions(FilteredRDD.scala:28)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)
      at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
      at scala.Option.getOrElse(Option.scala:120)
      at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)
      at org.apache.spark.rdd.RDD.take(RDD.scala:824)
      at org.apache.spark.rdd.RDD.first(RDD.scala:856)
      at pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite$$anonfun$3.apply$mcV$sp(SparkSeqAnalysisSuite.scala:28)
      at pl.elka.pw.sparkseq.util.SparkFunSuite$$anonfun$sparkSeqTest$1.apply$mcV$sp(SparkSeqFunSuite.scala:38)
      at pl.elka.pw.sparkseq.util.SparkFunSuite$$anonfun$sparkSeqTest$1.apply(SparkSeqFunSuite.scala:34)
      at pl.elka.pw.sparkseq.util.SparkFunSuite$$anonfun$sparkSeqTest$1.apply(SparkSeqFunSuite.scala:34)
      at org.scalatest.Transformer$$anonfun$apply$1.apply(Transformer.scala:22)
      at org.scalatest.Transformer$$anonfun$apply$1.apply(Transformer.scala:22)
      at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
      at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
      at org.scalatest.Transformer.apply(Transformer.scala:22)
      at org.scalatest.Transformer.apply(Transformer.scala:20)
      at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:158)
      at org.scalatest.Suite$class.withFixture(Suite.scala:1121)
      at org.scalatest.FunSuite.withFixture(FunSuite.scala:1559)
      at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:155)
      at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:167)
      at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:167)
      at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
      at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:167)
      at pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite.org$scalatest$BeforeAndAfter$$super$runTest(SparkSeqAnalysisSuite.scala:11)
      at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
      at pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite.runTest(SparkSeqAnalysisSuite.scala:11)
      at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:200)
      at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:200)
      at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
      at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
      at scala.collection.immutable.List.foreach(List.scala:318)
      at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
      at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
      at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
      at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:200)
      at org.scalatest.FunSuite.runTests(FunSuite.scala:1559)
      at org.scalatest.Suite$class.run(Suite.scala:1423)
      at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1559)
      at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:204)
      at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:204)
      at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
      at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:204)
      at pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite.org$scalatest$BeforeAndAfter$$super$run(SparkSeqAnalysisSuite.scala:11)
      at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
      at pl.elka.pw.sparkseq.seqAnalysis.SparkSeqAnalysisSuite.run(SparkSeqAnalysisSuite.scala:11)
      at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:442)
      at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:649)
      at sbt.TestRunner.runTest$1(TestFramework.scala:84)
      at sbt.TestRunner.run(TestFramework.scala:94)
      at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:224)
      at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:224)
      at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:212)
      at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:224)
      at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:224)
      at sbt.TestFunction.apply(TestFramework.scala:229)
      at sbt.Tests$$anonfun$7.apply(Tests.scala:196)
      at sbt.Tests$$anonfun$7.apply(Tests.scala:196)
      at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:45)
      at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:45)
      at sbt.std.Transform$$anon$4.work(System.scala:64)
      at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:237)
      at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:237)
      at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:18)
      at sbt.Execute.work(Execute.scala:244)
      at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:237)
      at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:237)
      at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:160)
      at sbt.CompletionService$$anon$2.call(CompletionService.scala:30)
      at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
      at java.util.concurrent.FutureTask.run(FutureTask.java:138)
      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
      at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
      at java.util.concurrent.FutureTask.run(FutureTask.java:138)
      at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
      at java.lang.Thread.run(Thread.java:662)
</failure>
</testcase>
  <system-out><![CDATA[]]></system-out>
  <system-err><![CDATA[]]></system-err>
</testsuite>
